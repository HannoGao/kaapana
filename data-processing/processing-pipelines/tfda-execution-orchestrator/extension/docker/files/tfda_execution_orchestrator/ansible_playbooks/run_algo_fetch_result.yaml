---
- hosts: localhost
  gather_facts: no
  vars:
    - target: "{{ target_host }}"
      default: "10.128.128.218"
  tasks:
    - add_host:
        name: "{{ target }}"
        groups: os_server

- name: Run algorithm on data in isolated environment and fetch results
  hosts: os_server
  strategy: free
  gather_facts: yes
  remote_user: "{{ remote_username }}"
  vars:
    #TODO: change hardcoded
    ansible_ssh_private_key_file: ~/.ssh/tfda_iso
    dst_results_dir: /home/{{ remote_username }}/results
  environment:
    PATH: '/home/{{ remote_username }}/.local/bin:{{ ansible_env.PATH }}'

  tasks:
    - name: Create results directory if it doesn't exist
      file:
        path: "{{ dst_results_dir }}"
        state: directory
        recurse: yes

    - name: Run user Shell script
      become: yes # -> not sure if a good idea to allow sudo to the shell script (actually, DON'T DO IT!)
      ## TODO: HARDCODED the user uploaded script name should be renamed to below file name or the extracted contents has to be pasted into below file name
      shell: bash /home/{{ remote_username }}/user_input_commands.sh
         
    # - name: Update submission tarfile name in MLCube config
    #   replace:
    #     path: /home/ubuntu/tarball/mlcube.yaml
    #     regexp: 'tar_file: /home/ubuntu/tarball/'
    #     replace: 'tar_file: /home/ubuntu/tarball/{{ subm_id }}.tar'

    # - name: Run Mini conda Installation for Cuda Support
    #   shell: bash /home/ubuntu/Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -p /home/ubuntu/miniconda3

    # - debug: msg="{{ '%H:%M:%S' | strftime }}"

    # - name: Get job ID of GPU monitoring task
    #   async_status:
    #     jid: "{{ gpu_and_ram_monitor.ansible_job_id }}"
    #   register: monitor_job_result
    #   until: monitor_job_result.finished
    #   retries: 350
    #   delay: 2
    #   ignore_errors: yes
  
    - name: Check if actually result files exist
      find:
        path: "{{ dst_results_dir }}"
        #patterns: 'result.yaml'
        file_type: file
        recurse: yes
      register: result_files
      failed_when: result_files.matched == 0

    - name: Create an archive of results into a zip file
      archive: 
        path: 
        - "{{ dst_results_dir }}"
        dest: "{{ dst_results_dir }}_{{ '%Y-%m-%d' | strftime }}.zip"
        format: zip


    - name: Fetch results from isolated environment
      become: yes
      ## Currently Ansible doesn't directly support directory/recursive copying from remote to local
      fetch:
        src: "{{ dst_results_dir }}_{{ '%Y-%m-%d' | strftime }}.zip"
        dest: "{{ results_path }}/"
        flat: yes
