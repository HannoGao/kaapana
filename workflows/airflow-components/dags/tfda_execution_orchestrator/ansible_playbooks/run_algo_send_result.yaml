---
- hosts: localhost
  gather_facts: no
  vars:
    - target: "{{ target_host }}"
      default: "10.128.128.218"
  tasks:
    - add_host:
        name: "{{ target }}"
        groups: os_server

- name: Run algorithm on data in isolated environment and send results back to parent data site
  hosts: os_server
  strategy: free
  gather_facts: yes
  remote_user: "{{ remote_username }}"
  vars:
    #TODO: change hardcoded
    ansible_ssh_private_key_file: ~/.ssh/tfda_iso.pem
  environment:
    PATH: '/home/ubuntu/.local/bin:{{ ansible_env.PATH }}'

  tasks:
    - name: Update submission tarfile name in MLCube config
      replace:
        path: /home/ubuntu/tarball/mlcube.yaml
        regexp: 'tar_file: /home/ubuntu/tarball/'
        replace: 'tar_file: /home/ubuntu/tarball/{{ subm_id }}.tar'

    - name: Run Mini conda Installation for Cuda Support
      shell: bash /home/ubuntu/Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -p /home/ubuntu/miniconda3

    - name: Convert docker to singularity using MLCube
      shell: mlcube configure --platform=singularity --mlcube=/home/ubuntu/tarball/mlcube.yaml
      ignore_errors: yes

    - name: Monitor GPU process
      shell: python3 /home/ubuntu/gpu_and_ram_monitoring.py
      async: 700
      poll: 0
      register: gpu_and_ram_monitor
      ignore_errors: yes   
    
    - name: Run MedPerf client on the submission
      shell: medperf --no-cleanup --storage=/home/ubuntu/medperf-env --platform=singularity --log=debug --infer-timeout=600 test -b {{ benchmark_id }} -m /home/ubuntu/tarball
      async: 650
      poll: 0
      ignore_errors: yes
    
    # - debug: msg="{{ '%H:%M:%S' | strftime }}"

    - name: Get job ID of GPU monitoring task
      async_status:
        jid: "{{ gpu_and_ram_monitor.ansible_job_id }}"
      register: monitor_job_result
      until: monitor_job_result.finished
      retries: 350
      delay: 2
      ignore_errors: yes
    
    - name: Kill process running Medperf if GPU consumption exceeds preset value
      command: pkill -f "/opt/conda/bin/python3"
      when: monitor_job_result.finished
      ignore_errors: yes
    
    - name: Check if logs exist
      stat:
        path: /home/ubuntu/medperf-env/logs/medperf.log
      register: log_file_check

    - name: Copy logs to results folder if available
      copy:
        src: /home/ubuntu/medperf-env/logs/medperf.log
        dest: /home/ubuntu/medperf-env/results/medperf.log
        remote_src: yes
      when: log_file_check.stat.exists

    - name: Create an archive of results into a zip file
      archive: 
        path: 
        - /home/ubuntu/medperf-env/results #/{{ benchmark_id }}
        dest: "/home/ubuntu/medperf-env/results_{{ subm_id }}_{{ '%Y-%m-%d' | strftime }}.zip"
        format: zip

    - name: Copy results back to the parent host
      become: yes
      ## Currently Ansible doesn't directly support directory/recursive copying from remote to local
      fetch:
        src: "/home/ubuntu/medperf-env/results_{{ subm_id }}_{{ '%Y-%m-%d' | strftime }}.zip"
        dest: "{{ subm_results_path }}/"
        flat: yes
    
    - name: Check if actually result files exist
      find:
        path: /home/ubuntu/medperf-env/results
        patterns: 'result.yaml'
        file_type: file
        recurse: yes
      register: result_files
      failed_when: result_files.matched == 0

    - name: Get name/s of singularity .sif file/s to be copied back to host
      find: 
        paths: "/home/ubuntu/tarball/workspace/.image"
        recurse: no 
        patterns: "*.sif"
      register: files_to_copy

    - name: Copy singularity file/s back to parent host
      fetch: 
        src: "{{ item.path }}"
        dest: "{{ singularity_path }}"
        flat: yes
      with_items: "{{ files_to_copy.files }}"